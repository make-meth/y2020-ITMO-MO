{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import *\n",
    "from scipy.optimize import minimize, least_squares\n",
    "printify = lambda f: lambda *args, **kwargs: print(f(*args, **kwargs), end='\\n' + '-'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 2.7605759509528782e-14\n",
      " hess_inv: array([[0.60000004, 0.20000003],\n",
      "       [0.20000003, 0.89999997]])\n",
      "      jac: array([1.57835371e-07, 3.14889244e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 3.14159273, -1.57079618])\n",
      "--------------------------------------------------\n",
      "      fun: 3.542141690395744e-17\n",
      " hess_inv: array([[ 0.625, -0.375],\n",
      "       [-0.375,  0.625]])\n",
      "      jac: array([2.99798231e-09, 2.99798231e-09])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([2.5, 2.5])\n",
      "--------------------------------------------------\n",
      "      fun: 2.500003966417107e-17\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-2.00000079e-08, -7.10542736e-15])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.        ,  8.99999999])\n",
      "--------------------------------------------------\n",
      "      fun: 1.9978021075792043e-19\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([1.08939355e-08, 1.08939364e-08])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.00575891,  9.00575891])\n",
      "--------------------------------------------------\n",
      "      fun: 2.500003966417107e-17\n",
      " hess_inv: None\n",
      "      jac: array([            nan, -7.10542736e-15])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.        ,  8.99999999])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pminimize = printify(minimize)\n",
    "\n",
    "pminimize(lambda x: (x[0] - torch.pi)**2 + (x[1] + torch.pi/2)**2, [0., 0.])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [0., 0.])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-2., 0.], bounds=[(-np.inf,-4), (-np.inf,np.inf)])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-5., 0.], bounds=[(-np.inf,-4), (-np.inf,np.inf)])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-5., 0.], bounds=[(-4,-4), (-np.inf,np.inf)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " active_mask: array([0., 0.])\n",
      "        cost: 1.2783752744478993e-12\n",
      "         fun: array([1.59898422e-06])\n",
      "        grad: array([ 3.61701446e-09, -1.80850731e-09])\n",
      "         jac: array([[ 0.00226207, -0.00113104]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 17\n",
      "        njev: 10\n",
      "  optimality: 3.6170144554807505e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([ 3.14272367, -1.57136183])\n",
      "--------------------------------------------------\n",
      " active_mask: array([0., 0.])\n",
      "        cost: 2.5731570692902734e-13\n",
      "         fun: array([7.17378153e-07])\n",
      "        grad: array([1.21523919e-09, 1.21523919e-09])\n",
      "         jac: array([[0.001694, 0.001694]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 16\n",
      "        njev: 11\n",
      "  optimality: 1.2152391925996551e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([2.50042349, 2.50042349])\n",
      "--------------------------------------------------\n",
      " active_mask: array([0, 0])\n",
      "        cost: 3.891221023383139e-14\n",
      "         fun: array([2.78970286e-07])\n",
      "        grad: array([2.94672394e-10, 2.94730453e-10])\n",
      "         jac: array([[0.00105629, 0.00105649]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 18\n",
      "        njev: 10\n",
      "  optimality: 2.947304534193074e-10\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([-4.48306459,  9.48359277])\n",
      "--------------------------------------------------\n",
      " active_mask: array([1, 0])\n",
      "        cost: 2.5403190678175113e-12\n",
      "         fun: array([2.25402709e-06])\n",
      "        grad: array([-6.76813025e-09, -6.76782779e-09])\n",
      "         jac: array([[-0.00300268, -0.00300255]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 16\n",
      "        njev: 16\n",
      "  optimality: 6.76782778631043e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([-4.        ,  8.99849866])\n",
      "--------------------------------------------------\n",
      " active_mask: array([1, 0])\n",
      "        cost: 2.5403190678175113e-12\n",
      "         fun: array([2.25402709e-06])\n",
      "        grad: array([-6.76813025e-09, -6.76782779e-09])\n",
      "         jac: array([[-0.00300268, -0.00300255]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 16\n",
      "        njev: 16\n",
      "  optimality: 6.76782778631043e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([-4.        ,  8.99849866])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pleast_squares = printify(least_squares)\n",
    "\n",
    "pleast_squares(lambda x: (x[0] - torch.pi)**2 + (x[1] + torch.pi/2)**2, [0., 0.])\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [0., 0.])\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [-4., 0.], bounds= ([-np.inf, -np.inf], [-4, np.inf]))\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [-4., 0.], bounds= ([-4 - 1e-10, -np.inf], [-4., np.inf]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a) Градиент"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}