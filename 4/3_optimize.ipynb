{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from bfgs_utils import *\n",
    "# from utils import *\n",
    "from scipy.optimize import minimize, least_squares, NonlinearConstraint\n",
    "printify = lambda f: lambda *args, **kwargs: print(f(*args, **kwargs), end='\\n' + '-'*50 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 2.7605759509528782e-14\n",
      " hess_inv: array([[0.60000004, 0.20000003],\n",
      "       [0.20000003, 0.89999997]])\n",
      "      jac: array([1.57835371e-07, 3.14889244e-07])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 3.14159273, -1.57079618])\n",
      "--------------------------------------------------\n",
      "      fun: 3.542141690395744e-17\n",
      " hess_inv: array([[ 0.625, -0.375],\n",
      "       [-0.375,  0.625]])\n",
      "      jac: array([2.99798231e-09, 2.99798231e-09])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([2.5, 2.5])\n",
      "--------------------------------------------------\n",
      "      fun: 2.500003966417107e-17\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-2.00000079e-08, -7.10542736e-15])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.        ,  8.99999999])\n",
      "--------------------------------------------------\n",
      "      fun: 1.9978021075792043e-19\n",
      " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([1.08939355e-08, 1.08939364e-08])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 12\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.00575891,  9.00575891])\n",
      "--------------------------------------------------\n",
      "      fun: 2.500003966417107e-17\n",
      " hess_inv: None\n",
      "      jac: array([            nan, -7.10542736e-15])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 3\n",
      "     njev: 4\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([-4.        ,  8.99999999])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pminimize = printify(minimize)\n",
    "\n",
    "pminimize(lambda x: (x[0] - torch.pi)**2 + (x[1] + torch.pi/2)**2, [0., 0.])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [0., 0.])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-2., 0.], bounds=[(-np.inf,-4), (-np.inf,np.inf)])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-5., 0.], bounds=[(-np.inf,-4), (-np.inf,np.inf)])\n",
    "pminimize(lambda x: ((x[0]-2) + (x[1]-3))**2, [-5., 0.], bounds=[(-4,-4), (-np.inf,np.inf)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " active_mask: array([0., 0.])\n",
      "        cost: 1.2783752744478993e-12\n",
      "         fun: array([1.59898422e-06])\n",
      "        grad: array([ 3.61701446e-09, -1.80850731e-09])\n",
      "         jac: array([[ 0.00226207, -0.00113104]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 17\n",
      "        njev: 10\n",
      "  optimality: 3.6170144554807505e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([ 3.14272367, -1.57136183])\n",
      "--------------------------------------------------\n",
      " active_mask: array([0., 0.])\n",
      "        cost: 2.5731570692902734e-13\n",
      "         fun: array([7.17378153e-07])\n",
      "        grad: array([1.21523919e-09, 1.21523919e-09])\n",
      "         jac: array([[0.001694, 0.001694]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 16\n",
      "        njev: 11\n",
      "  optimality: 1.2152391925996551e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([2.50042349, 2.50042349])\n",
      "--------------------------------------------------\n",
      " active_mask: array([0, 0])\n",
      "        cost: 3.891221023383139e-14\n",
      "         fun: array([2.78970286e-07])\n",
      "        grad: array([2.94672394e-10, 2.94730453e-10])\n",
      "         jac: array([[0.00105629, 0.00105649]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 18\n",
      "        njev: 10\n",
      "  optimality: 2.947304534193074e-10\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([-4.48306459,  9.48359277])\n",
      "--------------------------------------------------\n",
      " active_mask: array([1, 0])\n",
      "        cost: 2.5403190678175113e-12\n",
      "         fun: array([2.25402709e-06])\n",
      "        grad: array([-6.76813025e-09, -6.76782779e-09])\n",
      "         jac: array([[-0.00300268, -0.00300255]])\n",
      "     message: '`gtol` termination condition is satisfied.'\n",
      "        nfev: 16\n",
      "        njev: 16\n",
      "  optimality: 6.76782778631043e-09\n",
      "      status: 1\n",
      "     success: True\n",
      "           x: array([-4.        ,  8.99849866])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pleast_squares = printify(least_squares)\n",
    "\n",
    "pleast_squares(lambda x: (x[0] - torch.pi)**2 + (x[1] + torch.pi/2)**2, [0., 0.])\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [0., 0.])\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [-4., 0.], bounds= ([-np.inf, -np.inf], [-4, np.inf]))\n",
    "pleast_squares(lambda x: ((x[0]-2) + (x[1]-3))**2, [-4., 0.], bounds= ([-4 - 1e-10, -np.inf], [-4., np.inf]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-15.,  -8.,   0.,   8.,  40.,  65.]),)\n",
      "(tensor([-22.,  -8.,   0.,   8.,  40.,  90.]),)\n"
     ]
    }
   ],
   "source": [
    "coordinates = (torch.tensor([-2, -1, 0, 1, 2, 3]),)\n",
    "values = torch.tensor([16, 1, 0, 1, 16, 81], )\n",
    "print(torch.gradient(values, spacing = coordinates))\n",
    "print(torch.gradient(values, spacing = coordinates, edge_order=2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " active_mask: array([0, 0, 0])\n",
      "        cost: 5.467451202889606e-08\n",
      "         fun: array([0.00033068], dtype=float32)\n",
      "        grad: array([ 0.0001163 , -0.00025003, -0.00014195])\n",
      "         jac: array([[ 0.35171437, -0.75611669, -0.42926136]])\n",
      "     message: '`xtol` termination condition is satisfied.'\n",
      "        nfev: 48\n",
      "        njev: 42\n",
      "  optimality: 0.00025003239616096587\n",
      "      status: 3\n",
      "     success: True\n",
      "           x: array([ 1.00007520e+00, -1.72101474e-06,  9.99697044e-01])\n",
      "--------------------------------------------------\n",
      "PDL result for [1 0 1] is\n",
      "[0.99999952 0.         0.9999995 ]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def calc_poly(coeffs, points):\n",
    "    return sum(coeffs[i]*points**i for i in range(len(coeffs)))\n",
    "\n",
    "def test_torch_pdl(coeffs, points, **config):\n",
    "    coeffs, points = map(torch.tensor, [coeffs, points])\n",
    "    applied = calc_poly(coeffs, points)\n",
    "    f = lambda x: torch.linalg.norm(applied - calc_poly(x, points))\n",
    "    pleast_squares(f, [0]*len(coeffs), method='dogbox', **config)\n",
    "\n",
    "test_torch_pdl([1, 0, 1], [1, 0, -1])\n",
    "test_pdl([1, 0, 1], [1, 0, -1], epoch=40, tr0=1)\n",
    "print('-'*50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 4.5818709873963196e-11\n",
      " hess_inv: array([[0.00763893, 0.01252135, 0.0236093 , 0.04659247, 0.0932239 ],\n",
      "       [0.01252135, 0.02490652, 0.04729656, 0.09358024, 0.18715678],\n",
      "       [0.0236093 , 0.04729656, 0.09486791, 0.18792233, 0.37576475],\n",
      "       [0.04659247, 0.09358024, 0.18792233, 0.377341  , 0.75448228],\n",
      "       [0.0932239 , 0.18715678, 0.37576475, 0.75448228, 1.51357483]])\n",
      "      jac: array([-5.78899122e-06, -2.82251170e-06, -2.79807396e-06, -7.64314158e-06,\n",
      "        5.85476809e-06])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 372\n",
      "      nit: 25\n",
      "     njev: 60\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([0.99999925, 0.99999852, 0.99999706, 0.99999416, 0.99998833])\n",
      "--------------------------------------------------\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "[0.99999992 3.00000002]\n",
      "--------------------------------------------------\n",
      "      fun: 3.510679474496521e-16\n",
      " hess_inv: array([[ 0.27792958, -0.22208688],\n",
      "       [-0.22208688,  0.27789844]])\n",
      "      jac: array([-5.01945507e-09, -4.95590058e-09])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 30\n",
      "      nit: 9\n",
      "     njev: 10\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([1., 3.])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "wrap = lambda f: lambda args: f(*args)\n",
    "\n",
    "from scipy.optimize import rosen\n",
    "x0 = [1.3, 0.7, 0.8, 1.9, 1.2]\n",
    "pminimize(rosen, x0, method='BFGS', tol=1e-6)\n",
    "\n",
    "f = lambda size : lambda x,y : (x + 2*y - 7)**2 + (2*x + y - 5)**2\n",
    "grad = lambda x, y: [2*(x+2*y - 7)+2*2*(2*x + y -5), 2*2*(x+2*y-7) + 2*(2*x + y - 5)]\n",
    "print(BFGS(f, 0, [5,5], grad, 10)[-1])\n",
    "print('-'*50)\n",
    "\n",
    "pminimize(wrap(f(0)), [5,5], method='BFGS', tol=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}