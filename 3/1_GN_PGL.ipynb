{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Poly:\n",
    "    \"\"\"\"\n",
    "        c_0 + c_1 x + c_2 x^2 + .. + c_deg x^deg\n",
    "    \"\"\"\n",
    "    def __init__(self, *, deg=2, coeffs=None):\n",
    "        if coeffs is not None:\n",
    "            self.coeffs = np.array(coeffs)\n",
    "        else:\n",
    "            self.coeffs = np.ones(deg+1)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return sum(c_i * x**i for (i, c_i) in enumerate(self.coeffs))\n",
    "\n",
    "    def grad(self, x):\n",
    "        return np.array([x**i for (i, c_ip1) in enumerate(self.coeffs[:])]).T[0]\n",
    "\n",
    "    def hessian(self, x):\n",
    "        return np.diag(list(x**i for (i, c_ip1) in enumerate(self.coeffs[:])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm\n",
      "came close by [-2.47268872e-12 -2.40163445e-12 -7.94386779e-12 -4.60431693e-12]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([ 1.00000000e+00, -4.40536496e-13,  1.00000000e+00,  2.84217094e-14])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def regression(x, y, method, **config):\n",
    "    if config == {}:\n",
    "        config = {\"lr0\": 0.5, \"d\": 0.005, \"epoch\": 1000}\n",
    "    f = lambda x_poly: y - x_poly(x.T[0])\n",
    "    jacobi = lambda x_poly: np.array([- x_poly.grad(x[i]) for i in range(len(x))])\n",
    "    bs = method(f, np.zeros(len(x)), **config, jacobi=jacobi)\n",
    "    print('hm')\n",
    "    print(f'came close by {f(Poly(coeffs=bs[-1]))}')\n",
    "    return bs[-1]\n",
    "\n",
    "def gauss_newton(f, x, *, lr, epoch, jacobi):\n",
    "    points = np.zeros((epoch, len(x)))\n",
    "    x_poly = Poly(coeffs=x)\n",
    "    points[0] = x_poly.coeffs\n",
    "\n",
    "    for i in range(epoch):\n",
    "        j = jacobi(x_poly)\n",
    "        g = np.matmul(j.T, f(x_poly).reshape(-1,1))\n",
    "        h = np.matmul(j.T,j)\n",
    "        p = np.matmul(np.linalg.inv(h), g).T[0]\n",
    "        x_poly.coeffs -= lr * p\n",
    "        points[i] = x_poly.coeffs\n",
    "    return points\n",
    "\n",
    "regression(np.array([[-2], [3], [5], [4]]), np.array([5, 10, 26, 17]), gauss_newton, lr=1, epoch=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hm\n",
      "came close by [9.75554042e-07 4.78175113e-07 9.75554042e-07]\n",
      "result for [1 0 1] is\n",
      "[0.99999952 0.         0.9999995 ]\n",
      "hm\n",
      "came close by [-8.81133939e-05 -5.44572193e-05 -1.15601494e-04 -1.22060547e-04\n",
      "  2.02436770e-05]\n",
      "result for [1 0 1] is\n",
      "[ 1.00005446e+00 -4.82854548e-06  1.00005082e+00 -8.91550443e-06\n",
      " -3.41803695e-06]\n",
      "hm\n",
      "came close by [0.03387678 0.02097845 0.04519732 0.06230332 0.13832769 0.05692319]\n",
      "result for [1 0 1 0 1 2] is\n",
      "[9.79021546e-01 6.96281223e-04 9.81089080e-01 5.48161037e-03\n",
      " 1.00035233e+00 1.99948238e+00]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([9.79021546e-01, 6.96281223e-04, 9.81089080e-01, 5.48161037e-03,\n       1.00035233e+00, 1.99948238e+00])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dogleg_method_step(grad_k, hessian_k, trust_radius):\n",
    "    hessian_k_inv = np.linalg.inv(hessian_k)\n",
    "    dx_newton = -np.matmul(hessian_k_inv, grad_k)\n",
    "    dx_newton_norm = np.linalg.norm(dx_newton)\n",
    "\n",
    "    if dx_newton_norm <= trust_radius:\n",
    "        return dx_newton\n",
    "\n",
    "    dx_steepest = - np.dot(grad_k, grad_k) / np.dot(grad_k, np.dot(hessian_k,grad_k)) * grad_k\n",
    "    dx_steepest_norm = np.linalg.norm(dx_steepest)\n",
    "\n",
    "    if dx_steepest_norm >= trust_radius:\n",
    "        return trust_radius * dx_steepest / dx_steepest_norm\n",
    "\n",
    "    diff = dx_newton - dx_steepest\n",
    "    dx_steepest_x_diff = np.matmul(dx_steepest.T, diff)\n",
    "    discriminant = dx_steepest_x_diff ** 2 - np.linalg.norm(diff) ** 2 * \\\n",
    "                   (np.linalg.norm(dx_steepest) ** 2 - trust_radius ** 2)\n",
    "    tau = (-dx_steepest_x_diff + np.sqrt(discriminant)) / np.linalg.norm(diff) ** 2\n",
    "    return dx_steepest + tau * (dx_newton - dx_steepest)\n",
    "\n",
    "def trust_region_method(func, grad, hessian, x, tr0=1, tr_limit=2 ** 5, epoch=10, eta=0.1):\n",
    "    x_poly = Poly(coeffs=x)\n",
    "    points = np.zeros((epoch, len(x)))\n",
    "    points[0] = x_poly.coeffs\n",
    "    trust_radius = tr0\n",
    "    for i in range(1, epoch):\n",
    "        grad_k = grad(x_poly)\n",
    "        hessian_k = hessian(x_poly)\n",
    "        pk = dogleg_method_step(grad_k, hessian_k, trust_radius)\n",
    "\n",
    "        moved = Poly(coeffs=x_poly.coeffs + pk)\n",
    "\n",
    "        # Actual reduction.\n",
    "        act_red = sum(func(x_poly)**2) - sum(func(moved)**2)\n",
    "\n",
    "        # Predicted reduction.\n",
    "        # pred_red = -(np.dot(grad_k, pk) + 0.5 * np.dot(pk, np.dot(hessian_k , pk)))\n",
    "        pred_red = -(np.matmul(grad_k.T, pk) + 0.5 * np.matmul(pk.T, np.dot(hessian_k, pk)))\n",
    "        # print(f'{pred_red=}\\n{act_red=}')\n",
    "        # print(f'{trust_radius = }')\n",
    "        # Rho.\n",
    "        if pred_red == 0.0:\n",
    "            rhok = 1e99\n",
    "        else:\n",
    "            rhok = act_red / pred_red\n",
    "\n",
    "        # Calculate the Euclidean norm of pk.\n",
    "        norm_pk = np.linalg.norm(pk)\n",
    "\n",
    "        # Rho is close to zero or negative, therefore the trust region is shrunk.\n",
    "        if rhok < 0.25:\n",
    "            trust_radius = 0.25 * trust_radius\n",
    "        else:\n",
    "            # Rho is close to one and pk has reached the boundary of the trust region, therefore the trust region is expanded.\n",
    "            if rhok > 0.75 and norm_pk == trust_radius:\n",
    "                trust_radius = min(2.0 * trust_radius, tr_limit)\n",
    "            else:\n",
    "                trust_radius = trust_radius\n",
    "\n",
    "        # Choose the position for the next iteration.\n",
    "        if rhok > eta:\n",
    "            x_poly = moved\n",
    "        else:\n",
    "            x_poly = x_poly\n",
    "        points[i] = x_poly.coeffs\n",
    "    return points\n",
    "\n",
    "def regression_pdl(x, y, method, **config):\n",
    "    if config == {}:\n",
    "        config = {\"lr0\": 0.5, \"d\": 0.005, \"epoch\": 1000}\n",
    "    f = lambda x_poly: (y - x_poly(x.T[0]))\n",
    "    jacobi = lambda x_poly: np.array([- x_poly.grad(x[i]) for i in range(len(x))])\n",
    "    hessian = lambda x_poly: np.matmul(jacobi(x_poly).T, jacobi(x_poly))\n",
    "    grad = lambda x_poly: 2*np.matmul(jacobi(x_poly).T, f(x_poly))\n",
    "    bs = method(f, grad, hessian, np.zeros(len(x)), **config)\n",
    "    print('hm')\n",
    "    print(f'came close by {f(Poly(coeffs=bs[-1]))}')\n",
    "    return bs[-1]\n",
    "\n",
    "def test_pdl(coeffs, points, **config):\n",
    "    coeffs = np.array(coeffs)\n",
    "    points = np.array(points)\n",
    "    test_poly = Poly(coeffs=coeffs)\n",
    "    res = regression_pdl(np.array(points.reshape(-1,1)),test_poly(points),trust_region_method, **config)\n",
    "    print(f'result for {coeffs} is\\n{res}')\n",
    "    return res\n",
    "\n",
    "\n",
    "test_pdl([1, 0, 1], [1, 0, -1], epoch=40, tr0=1)\n",
    "test_pdl([1, 0, 1], [1, 0, -1, 2, 3], epoch=40, tr0=1, eta=0.05)\n",
    "test_pdl([1, 0, 1, 0, 1, 2], [1, 0, -1, 2, 3, -4], epoch=100, tr0=1, eta=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 94>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     86\u001B[0m     draw_polynom(adam_poly, points)\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# f = Poly(coeffs=[0,0,1])\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# x = np.array([-2,-1,0,1,2])\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m# draw_polynom(f, x, f(x))\u001B[39;00m\n\u001B[0;32m---> 94\u001B[0m \u001B[43mregression\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.35\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mregression\u001B[0;34m(x, y, batch_size, method, **config)\u001B[0m\n\u001B[1;32m     36\u001B[0m batch_choice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m batch_size: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(np\u001B[38;5;241m.\u001B[39marange(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), batch_size, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)))\n\u001B[1;32m     37\u001B[0m f_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m batch_size: \\\n\u001B[1;32m     38\u001B[0m                    \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39mb, batch\u001B[38;5;241m=\u001B[39mbatch_choice(batch_size): \\\n\u001B[1;32m     39\u001B[0m                        np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm((y[batch] \u001B[38;5;241m-\u001B[39m x_mat[batch]\u001B[38;5;241m.\u001B[39mdot(b)))\n\u001B[0;32m---> 40\u001B[0m bs \u001B[38;5;241m=\u001B[39m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf_batch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfull\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m f \u001B[38;5;241m=\u001B[39m f_batch_size(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcame close by \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf(\u001B[38;5;241m*\u001B[39mbs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36msgd_adam\u001B[0;34m(batch_size, f, x, lr0, epoch, alpha, beta)\u001B[0m\n\u001B[1;32m     18\u001B[0m v \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, epoch):\n\u001B[0;32m---> 20\u001B[0m     g \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mgrad_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     21\u001B[0m     m \u001B[38;5;241m=\u001B[39m alpha \u001B[38;5;241m*\u001B[39m m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39malpha)\u001B[38;5;241m*\u001B[39mg\n\u001B[1;32m     22\u001B[0m     v \u001B[38;5;241m=\u001B[39m beta \u001B[38;5;241m*\u001B[39m v \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta) \u001B[38;5;241m*\u001B[39m g\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mgrad_batch.<locals>.grad_help\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m      4\u001B[0m dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args)\n\u001B[1;32m      5\u001B[0m f \u001B[38;5;241m=\u001B[39m f_batch_size(batch_size)\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [(\n\u001B[1;32m      7\u001B[0m                 f(\u001B[38;5;241m*\u001B[39m[args[j] \u001B[38;5;241m+\u001B[39m (h \u001B[38;5;28;01mif\u001B[39;00m j \u001B[38;5;241m==\u001B[39m i \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)])\n\u001B[1;32m      8\u001B[0m                 \u001B[38;5;241m-\u001B[39m\n\u001B[1;32m      9\u001B[0m                 f(\u001B[38;5;241m*\u001B[39m[args[j] \u001B[38;5;241m-\u001B[39m (h \u001B[38;5;28;01mif\u001B[39;00m j \u001B[38;5;241m==\u001B[39m i \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)])\n\u001B[1;32m     10\u001B[0m         ) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m h)\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)]\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      4\u001B[0m dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(args)\n\u001B[1;32m      5\u001B[0m f \u001B[38;5;241m=\u001B[39m f_batch_size(batch_size)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [(\n\u001B[0;32m----> 7\u001B[0m                 \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m                 \u001B[38;5;241m-\u001B[39m\n\u001B[1;32m      9\u001B[0m                 f(\u001B[38;5;241m*\u001B[39m[args[j] \u001B[38;5;241m-\u001B[39m (h \u001B[38;5;28;01mif\u001B[39;00m j \u001B[38;5;241m==\u001B[39m i \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)])\n\u001B[1;32m     10\u001B[0m         ) \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m h)\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(dim)]\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mregression.<locals>.<lambda>.<locals>.<lambda>\u001B[0;34m(batch, *b)\u001B[0m\n\u001B[1;32m     35\u001B[0m k \u001B[38;5;241m=\u001B[39m x_mat\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     36\u001B[0m batch_choice \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m batch_size: \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mset\u001B[39m(np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(np\u001B[38;5;241m.\u001B[39marange(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]), batch_size, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)))\n\u001B[1;32m     37\u001B[0m f_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m batch_size: \\\n\u001B[1;32m     38\u001B[0m                    \u001B[38;5;28;01mlambda\u001B[39;00m \u001B[38;5;241m*\u001B[39mb, batch\u001B[38;5;241m=\u001B[39mbatch_choice(batch_size): \\\n\u001B[0;32m---> 39\u001B[0m                        np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm((y[batch] \u001B[38;5;241m-\u001B[39m \u001B[43mx_mat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m     40\u001B[0m bs \u001B[38;5;241m=\u001B[39m method(batch_size, f_batch_size, np\u001B[38;5;241m.\u001B[39mfull(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig)\n\u001B[1;32m     41\u001B[0m f \u001B[38;5;241m=\u001B[39m f_batch_size(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (1,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "def stochastic_jacobian(self, c, points):\n",
    "    jac = np.ndarray(shape=(len(points), len(c)))\n",
    "    for i in range(len(points)):\n",
    "        jac[i] = -self.function.grad(points[i][1:], c).T[0]\n",
    "    return jac\n",
    "\n",
    "def stochastic_grad(self, c, batch_count=1):\n",
    "    if not hasattr(self, \"pos\"):\n",
    "        self.pos = 0\n",
    "    batch = self.p[self.pos: self.pos + batch_count]\n",
    "    self.pos = (self.pos + batch_count) % len(self.p)\n",
    "    j = self.stochastic_jacobian(c, batch)\n",
    "    return 2 * np.matmul(j.T, self.get_r(c, batch))\n",
    "\n",
    "def grad_batch(f_batch_size, batch_size):\n",
    "    def grad_help(*args):\n",
    "        h = 1e-10\n",
    "        dim = len(args)\n",
    "        f = f_batch_size(batch_size)\n",
    "        return [(\n",
    "                        f(*[args[j] + (h if j == i else 0) for j in range(dim)])\n",
    "                        -\n",
    "                        f(*[args[j] - (h if j == i else 0) for j in range(dim)])\n",
    "                ) / (2 * h)\n",
    "                for i in range(dim)]\n",
    "    return grad_help\n",
    "\n",
    "def sgd_adam(batch_size, f, x, *, lr0, epoch, alpha, beta):\n",
    "    points = np.zeros((epoch, 3))\n",
    "    points[0] = x\n",
    "    m = 0\n",
    "    v = 0\n",
    "    for i in range(1, epoch):\n",
    "        g = np.array(grad_batch(f, batch_size)(*x))\n",
    "        m = alpha * m + (1-alpha)*g\n",
    "        v = beta * v + (1 - beta) * g**2\n",
    "\n",
    "        m_ = m/(1-alpha)\n",
    "        v_ = v/(1-beta)\n",
    "\n",
    "        x = x - lr0*m_/(np.sqrt(v_) + 1e-5)\n",
    "        points[i] = x\n",
    "    return points\n",
    "\n",
    "def regression(x, y, batch_size=1, method=sgd_adam, **config):\n",
    "    if config == {}:\n",
    "        config = {\"lr0\": 0.5, \"d\": 0.005, \"epoch\": 1000}\n",
    "    x_mat = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "    k = x_mat.shape[1]\n",
    "    batch_choice = lambda batch_size: list(set(np.random.choice(np.arange(x.shape[0]), batch_size, replace=False)))\n",
    "    f_batch_size = lambda batch_size: \\\n",
    "                       lambda *b, batch=batch_choice(batch_size): \\\n",
    "                           np.linalg.norm((y[batch] - x_mat[batch].dot(b)))\n",
    "    bs = method(batch_size, f_batch_size, np.full(3, 1), **config)\n",
    "    f = f_batch_size(x.shape[0])\n",
    "    print(f'came close by {f(*bs[-1])}')\n",
    "    ax = plt.figure().add_subplot()\n",
    "    X = np.arange(len(bs))\n",
    "    ax.plot(X, np.vectorize(f)(*bs.T))\n",
    "    ax.grid()\n",
    "    if len(x[0]) == 1:\n",
    "        draw_2d(x, y, bs[-1])\n",
    "    return bs[-1]\n",
    "\n",
    "def draw_2d(x, y, bs):\n",
    "    x = x.reshape(len(x))\n",
    "    ax = plt.figure().add_subplot()\n",
    "    ax.scatter(x, y)\n",
    "    ax.grid(True)\n",
    "    tmin = x.min() - 1\n",
    "    tmax = x.max() + 1\n",
    "    X = np.array([tmin, tmax])\n",
    "    Y = (lambda z: bs[0] + bs[1] * z)(X)\n",
    "    ax.add_line(mlines.Line2D(X, Y, color='green'))\n",
    "\n",
    "def draw_polynom(x_poly, x_points, y_points=None):\n",
    "    if y_points is None:\n",
    "        y_points = x_poly(x_points)\n",
    "    ax = plt.figure().add_subplot()\n",
    "    ax.scatter(x_points, y_points)\n",
    "    ax.grid()\n",
    "    X = np.linspace(x_points.min(), x_points.max(), 100)\n",
    "    ax.plot(X, x_poly(X))\n",
    "\n",
    "def test_adam(coeffs, points, **config):\n",
    "    coeffs = np.array(coeffs)\n",
    "    points = np.array(points)\n",
    "    test_poly = Poly(coeffs=coeffs)\n",
    "    res = regression(points.reshape(-1,1), test_poly(points), **config)\n",
    "    print(f'Adam result for {coeffs} is\\n{res}')\n",
    "    return res\n",
    "\n",
    "\n",
    "def test_compare(coeffs, points, config_pdl, config_adam):\n",
    "    coeffs = np.array(coeffs)\n",
    "    points = np.array(points)\n",
    "    pdl_poly = Poly(coeffs=test_pdl(coeffs, points, **config_pdl))\n",
    "    draw_polynom(pdl_poly, points)\n",
    "    adam_poly = Poly(coeffs=test_adam(coeffs, points, **config_adam))\n",
    "    draw_polynom(adam_poly, points)\n",
    "\n",
    "# f = Poly(coeffs=[0,0,1])\n",
    "# x = np.array([-2,-1,0,1,2])\n",
    "# draw_polynom(f, x, f(x))\n",
    "\n",
    "\n",
    "\n",
    "regression(np.array([[1], [2], [3]]), np.array([2, 4, 6]), lr0=0.1, epoch=1000, alpha=0.35, beta=0.2)\n",
    "# test_pdl([0, 2], [1, 2, 3], epoch=1000, tr0=0.1)\n",
    "\n",
    "# test_compare([1,0,1], [-2,0,4]\n",
    "#              , {'epoch': 100, 'tr0': 0.1}\n",
    "#              , {'lr0': 0.1, 'epoch': 1000, 'alpha': 0.35, 'beta':0.2})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}